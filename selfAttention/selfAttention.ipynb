{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "confident-macintosh",
   "metadata": {},
   "source": [
    "Self-attention is a sequence-to-sequence operation: a sequence of vectors goes in, and a sequence of vectors comes out. Let‚Äôs call the input vectors ùê±1,ùê±2,‚Ä¶,ùê±t and the corresponding output vectors ùê≤1,ùê≤2,‚Ä¶,ùê≤t. The vectors all have dimension k.\n",
    "\n",
    "To produce output vector ùê≤i, the self attention operation simply takes a weighted average over all the input vectors\n",
    "\n",
    "# ùê≤i=‚àëjwijùê±j.\n",
    "Where j indexes over the whole sequence and the weights sum to one over all j. The weight wij is not a parameter, as in a normal neural net, but it is derived from a function over ùê±i and ùê±j. The simplest option for this function is the dot product:\n",
    "\n",
    "# w‚Ä≤ij=ùê±iTùê±j.\n",
    "Note that ùê±i is the input vector at the same position as the current output vector ùê≤i. For the next output vector, we get an entirely new series of dot products, and a different weighted sum.\n",
    "The dot product gives us a value anywhere between negative and positive infinity, so we apply a softmax to map the values to [0,1] and to ensure that they sum to 1 over the whole sequence:\n",
    "\n",
    "# wij=exp w‚Ä≤ij‚àëjexp w‚Ä≤ij.\n",
    "And that‚Äôs the basic operation of self attention.\n",
    "\n",
    "<img src=\"http://peterbloem.nl/files/transformers/self-attention.svg\"/>\n",
    "ref: <a href=\"http://peterbloem.nl/blog/transformers\">http://peterbloem.nl/blog/transformers</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "hawaiian-thousand",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as f\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "behind-soldier",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = torch.nn.Embedding(1000,128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "stuffed-maximum",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 1, 128])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1 = embedding(torch.LongTensor([1]))\n",
    "x2 = embedding(torch.LongTensor([2]))\n",
    "x3 = embedding(torch.LongTensor([3]))\n",
    "x = torch.stack([x1, x2, x3])\n",
    "x.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "creative-evidence",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 1, 1])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wij = torch.bmm(x, x.transpose(1,2))\n",
    "wij.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "graphic-auction",
   "metadata": {},
   "outputs": [],
   "source": [
    "wij = f.softmax(wij, dim=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "disciplinary-antenna",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.bmm(wij, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "indonesian-honduras",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0235,  0.0644, -1.0557,  0.3499,  0.8542,  1.0027, -0.7468,\n",
       "          -0.7461,  0.8663, -0.3890,  0.4735,  2.3888,  0.9989, -0.7964,\n",
       "           0.7887, -0.2837, -0.0906,  0.3525, -0.2325, -1.0213,  0.7719,\n",
       "          -0.3725,  0.2081,  0.6937,  0.9120, -0.9780,  0.1345,  0.6599,\n",
       "           0.2458, -0.8819,  0.1030, -0.9069, -0.6137,  0.5116, -0.1451,\n",
       "          -0.0123,  0.2573, -0.9507, -0.2157, -0.3429, -0.1541, -0.2230,\n",
       "          -1.2359,  0.4929, -1.4787, -0.5101,  2.3545, -0.0465,  1.3382,\n",
       "          -0.3760,  1.2486, -1.9955, -0.3367, -1.4961,  1.0573,  0.4445,\n",
       "           2.0985,  1.2877, -0.1124,  1.9950, -0.2542,  0.3731, -0.4743,\n",
       "           2.5063, -0.9619, -0.0963, -0.0860, -0.2414, -1.1402, -1.2531,\n",
       "           0.7519,  0.3334, -0.1457, -0.7368,  0.7149, -1.8806, -0.7455,\n",
       "           0.4977, -0.9126, -1.1121,  2.6944,  0.9263,  0.7032, -0.6567,\n",
       "           2.0906, -0.1071, -1.4508,  0.0037,  0.6656,  0.0280,  1.0099,\n",
       "          -1.5742, -0.1638,  0.3440,  1.4420,  0.1871, -1.5006,  1.3072,\n",
       "          -1.0606, -0.5729,  0.0453, -0.5427,  0.2329,  0.8801,  3.4871,\n",
       "          -0.4735, -0.5616,  1.2248, -0.7911,  0.1048,  0.5913,  0.6932,\n",
       "           0.6933,  0.9847,  0.4599,  0.9971,  0.6249,  0.5077, -0.0730,\n",
       "           0.8350, -0.1545,  0.8778, -2.1521, -0.4970,  0.0470,  1.2294,\n",
       "           2.3258, -0.4489]],\n",
       "\n",
       "        [[ 0.5231,  0.9139,  0.0188,  0.4561,  0.7690, -0.8898,  1.4820,\n",
       "           0.4763, -0.0291, -0.4725,  0.0312,  0.2190, -0.4515, -1.3873,\n",
       "           1.5030, -0.7743, -1.1517,  1.1377,  0.3604, -1.2234, -0.1871,\n",
       "          -1.1211, -0.9648,  0.6425, -0.1363, -0.1821, -1.0896,  0.4986,\n",
       "          -0.9683,  0.3115,  0.4023, -0.1338,  0.2417,  0.6155,  1.9402,\n",
       "           0.8310, -0.6026,  0.4850,  0.1025,  0.5512, -0.6433,  0.7891,\n",
       "          -0.3485,  0.4433,  1.3153, -0.5189, -0.9925,  0.0775,  0.5342,\n",
       "           1.2027,  0.1954, -0.3463,  0.8829,  0.5943, -0.7035,  0.8867,\n",
       "           0.7293, -0.8969,  0.3691, -0.3164, -1.4776, -0.3885,  1.5908,\n",
       "           1.9002, -0.2489, -1.8056, -1.0877,  1.1326,  1.1423,  0.3412,\n",
       "           0.1164,  0.7182,  0.5411, -0.3841, -1.8213, -0.1030, -1.4855,\n",
       "           1.0746, -1.7891, -0.2312, -0.8962, -0.9199,  1.1671, -0.5421,\n",
       "          -0.8948, -0.2555,  0.3949,  0.4043,  0.4762,  0.4724,  0.1932,\n",
       "          -0.9123, -0.4225, -0.2158, -0.9674,  0.2023, -0.8070,  0.9712,\n",
       "          -0.0797, -0.0358, -0.2180,  2.2682,  0.5570,  1.0361,  0.4409,\n",
       "          -1.2218,  1.0051, -0.3921,  0.8891,  0.9608, -2.3070, -0.7753,\n",
       "           0.6182,  1.0522,  1.1906,  0.4791, -0.4863,  0.7194, -0.0887,\n",
       "          -0.6727,  0.2355,  0.7092,  0.9440, -0.4180, -0.2398,  0.9695,\n",
       "           1.6665,  1.7568]],\n",
       "\n",
       "        [[ 1.2427, -0.9390, -0.5736,  0.6142,  0.6209,  0.1752, -0.2521,\n",
       "          -0.1131, -0.8514, -0.7915, -0.0832,  0.0706, -1.1255,  1.8783,\n",
       "           0.2563,  1.0434, -0.3030, -1.8311, -0.3232,  0.3660, -0.1288,\n",
       "          -1.5029, -0.7234, -1.5447,  1.1649,  1.9861, -0.5690, -0.0142,\n",
       "           0.8220, -1.9445,  0.9525, -1.4494,  1.2525, -0.4340, -0.5231,\n",
       "           0.3742,  1.2799,  0.4246,  0.5385,  0.6525,  0.0505, -0.8340,\n",
       "           0.7383,  1.2764,  1.2845, -1.6497, -1.5659,  0.3191, -0.5023,\n",
       "           0.7008, -0.7642, -1.2169, -0.1904,  0.2511, -0.6318, -0.3963,\n",
       "           0.9083,  0.0050, -1.4121,  1.0627,  1.2226, -0.5445,  0.5715,\n",
       "           0.7936,  0.9134, -0.3773,  0.0344, -0.3926,  0.5039,  0.1038,\n",
       "           0.1654,  0.3010, -1.9363,  1.1540,  0.2692,  0.3968, -1.4598,\n",
       "          -0.0228, -0.3843, -0.2852, -1.1752,  0.0373,  0.2416, -1.1485,\n",
       "           1.8598, -0.5423, -0.4765, -0.4074,  1.3606,  1.5080,  0.9652,\n",
       "          -1.2011,  1.3933, -1.4607, -0.5842,  1.4096, -0.7174,  0.3129,\n",
       "          -0.8403,  0.1207,  0.1528,  0.2652,  0.7348,  0.2223, -0.4130,\n",
       "           1.1086,  0.0868, -1.1058,  2.2059,  0.1165,  0.3870, -0.9509,\n",
       "           0.5170,  0.3825,  1.6008, -1.4455,  1.7950, -0.1689,  0.0655,\n",
       "          -1.3758, -0.4618, -0.8906, -2.0774,  0.8270,  0.2474, -0.5980,\n",
       "          -2.7810, -0.3525]]], grad_fn=<BmmBackward0>)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "parental-liver",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
